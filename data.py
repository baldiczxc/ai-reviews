import pandas as pd
import re
from datasets import load_dataset
from tqdm import tqdm
import numpy as np

# ===================== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ =====================
OUTPUT_FILE = "filtered_wb_feedbacks.parquet"
MAX_ROWS = 192000000

# ===================== –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –æ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö =====================
def remove_personal_data(text):
    """–£–¥–∞–ª—è–µ—Ç –∏–º–µ–Ω–∞, —Ñ–∞–º–∏–ª–∏–∏ –∏ –¥—Ä—É–≥–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    if not isinstance(text, str):
        return text
    
    # –£–¥–∞–ª—è–µ–º –∏–º–µ–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–ò–º—è, –¥–æ–±—Ä—ã–π –¥–µ–Ω—å"
    text = re.sub(r'^[–ê-–Ø–Å][–∞-—è—ë]+[,!.]?\s+(–¥–æ–±—Ä—ã–π|–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ|–∏–∑–≤–∏–Ω–∏—Ç–µ)', '', text, flags=re.IGNORECASE)
    
    # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞—â–µ–Ω–∏—è —Å –∏–º–µ–Ω–∞–º–∏
    text = re.sub(r'(—É–≤–∞–∂–∞–µ–º—ã[–µ–π]|–¥–æ—Ä–æ–≥[–æ–π–∞—è])\s+[–ê-–Ø–Å][–∞-—è—ë]+', '', text, flags=re.IGNORECASE)
    
    # –£–¥–∞–ª—è–µ–º email –∞–¥—Ä–µ—Å–∞
    text = re.sub(r'\S+@\S+', '[EMAIL]', text)
    
    # –£–¥–∞–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
    text = re.sub(r'(\+7|8)[\s\-\(\)]*\d{3}[\s\-\(\)]*\d{3}[\s\-\(\)]*\d{2}[\s\-\(\)]*\d{2}', '[PHONE]', text)
    
    return text.strip()

# ===================== –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è =====================
def smart_filtering(df):
    """–£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–±–∏—Ä–∞–µ—Ç —Ä–µ–∫–ª–∞–º—É –∏ —à–∞–±–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"""
    print("–ó–∞–ø—É—Å–∫ —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏...")

    results = []
    cleaned_texts = []
    cleaned_answers = []

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è —Ä–µ–∫–ª–∞–º—ã
    ad_phrases = [
        # –ü—Ä—è–º—ã–µ –ø—Ä–∏–∑—ã–≤—ã
        '–∂–¥–µ–º –≤–∞—Å —Å–Ω–æ–≤–∞', '–∂–¥—ë–º –≤–∞—Å —Å–Ω–æ–≤–∞',
        '–∂–¥–µ–º –∑–∞ –ø–æ–∫—É–ø–∫–∞–º–∏', '–∂–¥—ë–º –∑–∞ –ø–æ–∫—É–ø–∫–∞–º–∏',
        '–ø—Ä–∏—è—Ç–Ω—ã—Ö –ø–æ–∫—É–ø–æ–∫', '–Ω–∞–¥–µ–µ–º—Å—è —É–≤–∏–¥–µ—Ç—å –≤–∞—Å —Å–Ω–æ–≤–∞',
        '—Å –Ω–∞–¥–µ–∂–¥–æ–π –≤–∏–¥–µ—Ç—å', '–±—É–¥–µ–º —Ä–∞–¥—ã –≤–∏–¥–µ—Ç—å',
        '–∂–¥–µ–º –≤ –Ω–∞—à–µ–º –º–∞–≥–∞–∑–∏–Ω–µ', '–∂–¥—ë–º –≤ –Ω–∞—à–µ–º –º–∞–≥–∞–∑–∏–Ω–µ',
        '–ø–æ–∫—É–ø–∞–π', '–∑–∞–∫–∞–∑—ã–≤–∞–π', '–ø—Ä–∏–æ–±—Ä–µ—Ç–∞–π',
        
        # –†–µ–∫–ª–∞–º–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        '—Å–∫–∏–¥–∫', '–≤—ã–≥–æ–¥–Ω', '–∞–∫—Ü–∏', '—Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ',
        '–ª—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ', '—É—Å–ø–µ–π—Ç–µ –∑–∞–∫–∞–∑–∞—Ç—å', '—É—Å–ø–µ–π—Ç–µ –∫—É–ø–∏—Ç—å',
        '–ø–æ–¥–∞—Ä–æ–∫ –∫–∞–∂–¥–æ–º—É', '–∫–∞—Ç–∞–ª–æ–≥', '–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç',
        
        # –ó–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
        '—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å', '—Å–æ–≤–µ—Ç—É–µ–º –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å',
        '–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞', '–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫–∂–µ',
        
        # –ü—Ä–æ–¥–∞–≤–µ—Ü —Å–∞–º —Å–µ–±—è —Ö–≤–∞–ª–∏—Ç
        '–Ω–∞—à–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏', '–Ω–∞—à–∏ –ø–æ–¥—Ä—É–≥–∏', '–º—ã —É–≤–µ—Ä–µ–Ω—ã —á—Ç–æ',
        '—É–≤–µ—Ä–µ–Ω—ã —á—Ç–æ –≤—ã —Å–º–æ–∂–µ—Ç–µ –ø–æ–¥–æ–±—Ä–∞—Ç—å'
    ]

    for _, row in tqdm(df.iterrows(), total=len(df), desc="–£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è"):
        original_text = str(row['text'])
        original_answer = str(row['answer'])

        # –û—á–∏—â–∞–µ–º –æ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        cleaned_text = remove_personal_data(original_text)
        cleaned_answer = remove_personal_data(original_answer)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ
        if len(cleaned_text) < 10 or len(cleaned_answer) < 10:
            results.append(False)
            cleaned_texts.append(cleaned_text)
            cleaned_answers.append(cleaned_answer)
            continue

        answer_lower = cleaned_answer.lower()

        # 1. –ñ–ï–°–¢–ö–ò–ï –ö–†–ò–¢–ï–†–ò–ò –û–¢–°–ï–ò–í–ê–ù–ò–Ø (—Ä–µ–∫–ª–∞–º–∞, —à–∞–±–ª–æ–Ω—ã)
        is_advertisement = (
            re.search(r'–∞—Ä—Ç\.\s*\d+|–∞—Ä—Ç–∏–∫—É–ª\s*\d+', answer_lower) or
            re.search(r'—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º.*\d+|–ø—Ä–µ–¥–ª–∞–≥–∞–µ–º.*\d+', answer_lower) or
            re.search(r'[#‚Ññ]\d+', answer_lower) or
            any(phrase in answer_lower for phrase in ad_phrases)
        )
        is_template = (
            len(cleaned_answer) < 25 or
            answer_lower.startswith(('—Å–ø–∞—Å–∏–±–æ', '–±–ª–∞–≥–æ–¥–∞—Ä', '–∏–∑–≤–∏–Ω')) and len(cleaned_answer) < 50 or
            any(phrase in answer_lower for phrase in [
                '—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤', '–±–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤', '–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É',
                '–Ω–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º', '–ø–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞–º', '–∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–π —Ç–µ–ª–µ—Ñ–æ–Ω',
                '–≤–∞—à –æ—Ç–∑—ã–≤ –æ—á–µ–Ω—å –≤–∞–∂–µ–Ω', '–±—É–¥–µ–º —Ä–∞–¥—ã –ø–æ–º–æ—á—å', '–ø—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è'
            ])
        )

        has_junk = (
            re.search(r'http|www|\.ru|\.com', cleaned_answer) or
            re.search(r'[0-9]{10,}', cleaned_answer) or
            '[EMAIL]' in cleaned_answer or
            '[PHONE]' in cleaned_answer
        )

        # 2. –ö–†–ò–¢–ï–†–ò–ò –ö–ê–ß–ï–°–¢–í–ï–ù–ù–û–ì–û –û–¢–í–ï–¢–ê
        text_words = set(word for word in cleaned_text.lower().split() if len(word) > 4)
        answer_words = set(cleaned_answer.lower().split())
        common_words = text_words & answer_words
        has_relevance = len(common_words) > 0

        has_quality = (
            len(cleaned_answer.split()) > 8 and  # –ù–µ –º–µ–Ω–µ–µ 9 —Å–ª–æ–≤
            any(char in cleaned_answer for char in '.!?') and  # –ï—Å—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è
            any(word in answer_lower for word in [  # –°–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω—ã–µ —Å–ª–æ–≤–∞
                '–∫–∞—á–µ—Å—Ç–≤', '–¥–æ—Å—Ç–∞–≤–∫', '—Ä–∞–∑–º–µ—Ä', '—Ü–≤–µ—Ç', '–º–∞—Ç–µ—Ä–∏–∞–ª',
                '–≥–∞—Ä–∞–Ω—Ç–∏', '–æ–±–º–µ–Ω', '–≤–æ–∑–≤—Ä–∞—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥', '—Å–æ–≤–µ—Ç—É',
                '–ø—Ä–æ–±–ª–µ–º', '—Ä–µ—à–µ–Ω', '–∏–∑–º–µ–Ω–µ–Ω', '—É–ª—É—á—à–µ–Ω', '–∏—Å–ø—Ä–∞–≤–ª–µ–Ω'
            ]) and
            # –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ñ—Ä–∞–∑
            not any(ad_phrase in answer_lower for ad_phrase in ['–∫—É–ø–∏—Ç', '–∑–∞–∫–∞–∑', '–ø–æ–∫—É–ø–∫', '–º–∞–≥–∞–∑–∏–Ω', '–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç'])
        )

        # 3. –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï - –∂–µ—Å—Ç–∫–æ –æ—Ç—Å–µ–∏–≤–∞–µ–º —Ä–µ–∫–ª–∞–º—É
        should_keep = (
            has_relevance and
            has_quality and
            not is_template and
            not has_junk and
            not is_advertisement
        )

        results.append(should_keep)
        cleaned_texts.append(cleaned_text)
        cleaned_answers.append(cleaned_answer)

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    filtered_df = df.copy()
    filtered_df['text_cleaned'] = cleaned_texts
    filtered_df['answer_cleaned'] = cleaned_answers
    filtered_df = filtered_df[results]

    return filtered_df

# ===================== –ü–æ–∫–∞–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ =====================
def show_real_examples(original_df, filtered_df, num_examples=5):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–æ –∏ –ø–æ—Å–ª–µ"""
    print(f"\n=== –†–ï–ê–õ–¨–ù–´–ï –ü–†–ò–ú–ï–†–´ (–∏–∑ {len(filtered_df)} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö) ===")
    
    if len(filtered_df) > 0:
        sample_indices = np.random.choice(len(filtered_df), min(num_examples, len(filtered_df)), replace=False)
        
        for i, idx in enumerate(sample_indices):
            filtered_row = filtered_df.iloc[idx]
            original_idx = filtered_row.name
            
            if original_idx in original_df.index:
                original_row = original_df.loc[original_idx]
                
                print(f"\n--- –ü—Ä–∏–º–µ—Ä {i+1} ---")
                print(f"üìù –ë–´–õ–û - –û—Ç–∑—ã–≤: {original_row['text']}")
                print(f"üí¨ –ë–´–õ–û - –û—Ç–≤–µ—Ç: {original_row['answer']}")
                print(f"‚ú® –°–¢–ê–õ–û - –û—Ç–∑—ã–≤: {filtered_row['text_cleaned']}")
                print(f"‚úÖ –°–¢–ê–õ–û - –û—Ç–≤–µ—Ç: {filtered_row['answer_cleaned']}")
                
                # –ê–Ω–∞–ª–∏–∑ –ø–æ—á–µ–º—É —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏/–æ—Ç—Å–µ—è–ª–∏
                answer_lower = filtered_row['answer_cleaned'].lower()
                if any(word in answer_lower for word in ['–∫–∞—á–µ—Å—Ç–≤', '–≥–∞—Ä–∞–Ω—Ç–∏', '—Ä–µ–∫–æ–º–µ–Ω–¥']):
                    print("üîç –°–æ—Ö—Ä–∞–Ω–µ–Ω: —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—á–µ—Å—Ç–≤–µ")
                elif any(word in answer_lower for word in ['–ø—Ä–æ–±–ª–µ–º', '—Ä–µ—à–µ–Ω', '–∏—Å–ø—Ä–∞–≤–ª–µ–Ω']):
                    print("üîç –°–æ—Ö—Ä–∞–Ω–µ–Ω: –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
                elif len(filtered_row['answer_cleaned'].split()) > 12:
                    print("üîç –°–æ—Ö—Ä–∞–Ω–µ–Ω: —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç")
                else:
                    print("üîç –°–æ—Ö—Ä–∞–Ω–µ–Ω: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ —Ä–µ–∫–ª–∞–º—ã")
                
                print("-" * 80)

# ===================== –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è =====================
def main():
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º wb-feedbacks...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    wb = load_dataset("nyuuzyou/wb-feedbacks", split="train")
    wb = wb.filter(lambda x: (x.get("text") or "") != "" and (x.get("answer") or "") != "")
    
    if len(wb) > MAX_ROWS:
        wb = wb.select(range(MAX_ROWS))
    
    original_df = pd.DataFrame(wb)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(original_df)} —Å—Ç—Ä–æ–∫")
    
    # –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    filtered_df = smart_filtering(original_df)
    print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_df)} —Å—Ç—Ä–æ–∫")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    show_real_examples(original_df, filtered_df)
    
    if len(filtered_df) > 0:
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        filtered_df['formatted_text'] = "–û—Ç–∑—ã–≤: " + filtered_df['text_cleaned'] + "\n–û—Ç–≤–µ—Ç: " + filtered_df['answer_cleaned']
        filtered_df.to_parquet(OUTPUT_FILE, index=False)
        print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(filtered_df)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ {OUTPUT_FILE}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"–ò—Å—Ö–æ–¥–Ω–æ: {len(original_df)} —Å—Ç—Ä–æ–∫")
        print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_df)} —Å—Ç—Ä–æ–∫")
        print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö: {len(filtered_df)/len(original_df)*100:.1f}%")
        print(f"üö´ –û—Ç—Å–µ—è–Ω–æ —Ä–µ–∫–ª–∞–º—ã –∏ —à–∞–±–ª–æ–Ω–æ–≤: {len(original_df) - len(filtered_df)} —Å—Ç—Ä–æ–∫")
    
    else:
        print("‚ùå –ù–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

if __name__ == "__main__":
    main()